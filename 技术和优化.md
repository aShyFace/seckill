# 1 业务优化
## 1.1 集群session共享问题
### 描述
多台Tomcat并不共享session存储空间，当请求切换到不同tomcat服务时导致数据丢失的问题
业务流程：
1. 用户填写手机号，**点击**获取验证码，后端生成随机验证码返回，同时把 手机号-验证码 的对应关系保存到session
2. 用户提交手机号和验证码，后端根据手机号判断用户是否存在，存在则保存用户信息到session中；否则转到登陆界面或直接创建新用户
3. 之后用户再次登陆，后端则根据cookie中保存的sessionid获取用户信息，若有则放行

### 方案
session的替代方案应该满足
- 数据共享
- 内存存储
- key、value结构

使用redis存储后的流程：
1. 用户填写手机号，点击获取验证码，后端生成随机验证码返回，同时把 手机号-验证码 的对应关系保存到redis
2. 用户提交手机号和验证码，**后端根据第1步存入的 手机号-验证码 判断用户是否存在**，存在则保存用户信息到redis中（生成随机uuid）；否则转到登陆界面或直接创建新用户
3. 之后用户再次登陆，后端则根据cookie中保存的sessionid获取用户信息，若有则放行
在登陆业务中，要从session中分离出来的数据有 验证码、用户信息、token（用于）。
- key-手机号（与验证码唯一对应的就行），value-验证码
- key-"login:code"（使用业务逻辑来命名），value-用户信息
<br/><br/>


## 1.2 缓存更新策略
1. 内存淘汰，也就是redis自己管理。适合 一致性要求低，变化不大的数据。如首页模块的类型（一般都是什么外卖、超市、药店什么的）  
2. 超时剔除，手动设置超时时间  
3. 主动更新，即在数据库修改的同时更新缓存，同时用超时方案兜底。适合 一致性要求高的业务。如店铺详情的缓存  

### 商户缓存更新
由于商户信息的即时性要求不高，所以使用先改库再删缓存的方式更新数据。（延时双删也行）
<br/><br/><br/>



# 2 秒杀业务
## 2.1 超买问题
问题描述：
1. mybatisplus自带函数无法满足秒杀业务，但是其提供的update会返回更新数据条数。数据条数是否更新等价于是否抢到券，**没有该信息会出现超买现象**。
2. 教程提供的代码中，直接在service中编写sql语句，增加了代码的耦合性——如果表字段发生改变，service代码也需要进行更改。

解决：
1. 自定义的mapper.xml需要添加 SELECT ROW_COUNT(); 返回更新数据条数。
2. 同时需要在配置文件中（jdbcurl）开启 allowMultiQueries=true。
<br/><br/>


# 2.2 synchronized在@transactional所在方法内部使用，导致的并发问题
场景：实现秒杀优惠券一人一单时，在查询订单数量之后 spring提交事务之前，会出现超买问题（并发问题）。解决方法是添加synchronized，也就是悲观锁，但还是出了问题。
>乐观锁是基于“版本号”实现的，也就是要求操作的时候数据必须存在，即，只能在update的时候使用。该业务是添加订单，insert操作，用不了乐观锁

原因：@transactional由spring管理，整个方法执行完后才会提交事务。synchronized修饰的代码块执行后，就会自动释放锁。导致 **synchronized执行后，@transactional提交前** 这段时间，其它线程有机会访问代码，导致依然会出现超买现象。

解决：
1. synchronized不能加在方法上，应该加在调用者的那行代码上。加在方法上是 先释放锁，在提交事务（会出现多线程问题）；加在调用者上是 先提交事务（因为方法执行结束后@transactional就提交了），再释放锁  
2. 调用这个方法的代码，需要使用代理对象来调用这个方法。即
```
    VoucherOrderService proxy = (VoucherOrderService) AopContext.currentProxy();
    // createVoucherOrder默认是 this.createVoucherOrder，代理对象不能用this
    proxy.createVoucherOrder(voucherId); 
```
<br/><br/>



## 2.3 多线程安全问题
集群问题：
1. 多线程的每个线程都拥有自己的锁监视器，导致锁不共享，它们应该使用共同的锁才能避免超买。解决方案：使用redis的setnx锁。setIfAbsent（也就是setnx）根据key表示不同的锁，每个用户秒杀的商品 在redis中都拥有唯一的锁。
2. 误删问题：拥有锁的线程挂掉或者执行花费了太长的时间 导致redis自动把锁删了——如果这时候其它线程获取了锁而当前线程释放了锁，就会出现锁误删。解决方案：value表示拥有锁的线程（uuid+线程id），不是该value的线程不能释放锁，这样就避免了锁误删。
3. 误删问题：2判断条件通过后，线程阻塞了。解决：使用lua脚本实现判断和删除数据的原子性。
<br/><br/>


## 2.4 全局ID生成器
“订单ID”的要求：
1. 分布式下id全局唯一
2. 数据量大，存入数据库时需要分表，加上mysql只能保证单表id的自增，导致分表之后订单id不是自增了。由于数据库底层用的b+树——叶子节点有序，无序的id会消耗不必要的性能
3. 无明显递增规律

解决：使用时间戳拼接redis自增函数（升序拼接升序还是升序）
<br/><br/><br/>



# 3 秒杀业务优化
## 3.1 使用redis缓存
业务流程
1. 判断库存是否充足
2. 判断当前用户是否已经下单
3. 如果未下单，则扣减库存

未优化之前，这三步都得查询数据库。第3步更新库存时，sql里有“where stock > 0”的判断，所以实际上把第1步去掉也能正常执行，但毕竟判断1次就能pass的别判断3次，第1步算是个优化吧。  

优化之后，这三步走的是redis。问题是 @Transactional标注的函数所包含的数据库操作，其对应的redis操作都要写进lua脚本中（或则包括在锁中）。那么第1步要不要包含在里面呢？答：如果第3步中没有判断库存，那就要包括；否则包不包括没有影响。
<br/>


## 3.2 消息队列知识点
1. 消息与交换机是一对一关系，交换机与队列是多对多关系，队列与消费者是多对多关系。
2. 在一个队列只里，同一个消息只能被消费一次
3. 交换机可以把一个消息发送到多个队列，发送到几个队列，这个消息就会被消费几次
<br/>


## 3.3 消息队列优化
消息发送过程：  publisher -> exchange -> queue -> consumer
要保证这个过程安全地走完，其实只要做到两点就行了：
1. 保证 发送者能够送达消息，而不是发送消息后就不管了
2. 保证 MQ宕机时，消息不丢失（MQ默认模式是 持久化）
3. 保证 消费者能够处理消息，处理好中途宕机等程序中断问题

### 3.2.1 生产者
消息传递过程中的丢失
1. publisher发送的消息未送到exchange。生产者确认机制，保证生产者不会把消息弄丢，逻辑为（需要有一个全局唯一的id来区分不同的消息）
    - 消息未发送到exchange：返回 publisher-confirm nack
    - 消息未发送到队列：返回 publisher-return ack
    - 消息发送到队列：返回 publisher-confirm ack
2. exchange发送的消息未送到queue。消息持久化到硬盘
3. consumer收到消息后未消费就宕机。消费者消息确认和消费失败重试
<br/>

### 3.2.2 消费者
消费者消费失败后，MQ默认会再次发送消息到消费者，导致MQ和消费者无限循环，增大MQ的压力。解决方法有两种：
1. 把该消息放置队列尾部（队列里只有这个消息时，还是会出现无限循环的情况）
2. 利用Spring的retry机制，让消费者出现异常时本地重试，而不是无限requeue到消息队列

对于方法2，重试次数用完后mq会调用指定的接口来处理这个消息，该接口包含三种处理方式（三个方法）：
1. RejectAndDontRequeueRecoverer:重试耗尽后，直接reject，丢弃消息。默认就是这种方式
2. ImmediateRequeueMessageRecoverer:本地重试耗尽后，返回nack，消息重新入队，一定程度上缓解了无限循环的情况
3. RepublishMessageRecoverer:重试耗尽后，将失败消息投递到指定的交换机
<br/>

### 3.2.3 解决消息堆积
1. 队列多绑定消费者
2. 消费者内部使用线程池执行业务
3. 增加队列容量（直接增加大小或者使用惰性队列）
<br/><br/><br/>